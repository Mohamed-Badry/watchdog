{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f05191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modern Tooling\n",
    "from loguru import logger\n",
    "from rich.logging import RichHandler\n",
    "from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeRemainingColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd96fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "SATNOGS_API_URL = \"https://db.satnogs.org/api/telemetry/\"\n",
    "API_TOKEN = os.getenv('SATNOGS_API_TOKEN')\n",
    "MAX_RETRIES = 5\n",
    "CHUNK_SIZE_DAYS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8359cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate Limiting (SatNOGS: ~1 req/sec is safe, or 240/hr = 1 req/15s conservatively)\n",
    "# We'll stick to a safe 2s delay between requests to avoid hitting 429s constantly.\n",
    "REQUEST_DELAY_SECONDS = 2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7247ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verified NORAD IDs\n",
    "TARGETS = {\n",
    "    \"25397\": \"GO-32 (TechSat-1B)\",\n",
    "    \"39090\": \"STRaND-1\",\n",
    "    \"40043\": \"TigriSat\",\n",
    "    \"40012\": \"UniSat-6\",\n",
    "    \"52897\": \"STEP CubeLab-II\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e586a1d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- LOGGING SETUP ---\n",
    "logger.configure(handlers=[\n",
    "    {\n",
    "        \"sink\": RichHandler(markup=True, rich_tracebacks=True, show_time=False),\n",
    "        \"format\": \"{message}\",\n",
    "        \"level\": \"INFO\"\n",
    "    },\n",
    "    {\n",
    "        \"sink\": \"logs/downloader_{time}.log\", \n",
    "        \"rotation\": \"10 MB\", \n",
    "        \"retention\": \"1 week\",\n",
    "        \"format\": \"{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}\",\n",
    "        \"level\": \"DEBUG\"\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0adb5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SatNOGSDownloader:\n",
    "    def __init__(self, output_dir=\"data/raw\"):\n",
    "        self.token = API_TOKEN\n",
    "        self.base_url = SATNOGS_API_URL\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if not self.token:\n",
    "            logger.critical(\"SATNOGS_API_TOKEN not found in .env file.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'Authorization': f'Token {self.token}',\n",
    "            'Accept': 'application/json',\n",
    "        })\n",
    "\n",
    "    def _get_chunk_filename(self, norad_id: str, chunk_start: datetime) -> Path:\n",
    "        sat_dir = self.output_dir / str(norad_id)\n",
    "        sat_dir.mkdir(parents=True, exist_ok=True)\n",
    "        return sat_dir / f\"{chunk_start.strftime('%Y-%m-%d')}.jsonl\"\n",
    "\n",
    "    def download_chunk(self, norad_id: str, chunk_start: datetime, chunk_end: datetime, progress_task_id, progress_obj):\n",
    "        \"\"\"\n",
    "        Downloads frames for a specific time chunk and streams them to disk.\n",
    "        \"\"\"\n",
    "        outfile = self._get_chunk_filename(norad_id, chunk_start)\n",
    "        sat_name = TARGETS.get(norad_id, \"Unknown\")\n",
    "        date_str = chunk_start.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Display Context (Persist in logs)\n",
    "        log_prefix = f\"[cyan]{sat_name}[/] ([dim]{norad_id}[/]) | [green]{date_str}[/]\"\n",
    "\n",
    "        # Checkpointing\n",
    "        if outfile.exists() and outfile.stat().st_size > 0:\n",
    "            logger.info(f\"{log_prefix} | Skipped (Exists)\")\n",
    "            return\n",
    "\n",
    "        params = {\n",
    "            'satellite': norad_id,\n",
    "            'format': 'json',\n",
    "            'start': chunk_start.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            'end': chunk_end.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            'page': 1\n",
    "        }\n",
    "\n",
    "        # Update Progress Bar (Show what we are working on)\n",
    "        progress_obj.update(progress_task_id, description=f\"Fetching {log_prefix}...\")\n",
    "\n",
    "        frames_downloaded = 0\n",
    "        chunk_seen_hashes = set() # Circuit breaker for infinite page loops\n",
    "        \n",
    "        # Cursor Pagination Logic\n",
    "        # We start with the base URL and params. Subsequent requests use the 'next' URL from the API.\n",
    "        current_url = self.base_url\n",
    "        current_params = params \n",
    "\n",
    "        with open(outfile, 'a') as f:\n",
    "            while True:\n",
    "                retry_count = 0\n",
    "                success = False\n",
    "                \n",
    "                # Enforce Rate Limit (Pre-emptive)\n",
    "                time.sleep(REQUEST_DELAY_SECONDS)\n",
    "\n",
    "                # Retry Loop\n",
    "                while retry_count < MAX_RETRIES:\n",
    "                    try:\n",
    "                        # Use params only if we are hitting the base URL (first page)\n",
    "                        # If we are following a 'next' link, params are already in the string.\n",
    "                        req_params = current_params if current_url == self.base_url else None\n",
    "                        \n",
    "                        response = self.session.get(current_url, params=req_params, timeout=15)\n",
    "                        \n",
    "                        if response.status_code == 429:\n",
    "                            sleep_time = 60 * (retry_count + 1)\n",
    "                            logger.warning(f\"{log_prefix} | [yellow]Rate Limit (429)[/] Sleeping {sleep_time}s...\")\n",
    "                            \n",
    "                            # Visual Countdown\n",
    "                            for remaining in range(sleep_time, 0, -1):\n",
    "                                progress_obj.update(progress_task_id, description=f\"[yellow]Rate Limit: Sleeping {remaining}s...[/] {log_prefix}\")\n",
    "                                time.sleep(1)\n",
    "                            \n",
    "                            # Restore description\n",
    "                            progress_obj.update(progress_task_id, description=f\"Fetching {log_prefix}...\")\n",
    "                            retry_count += 1\n",
    "                            continue\n",
    "                        \n",
    "                        if response.status_code == 404:\n",
    "                            logger.warning(f\"{log_prefix} | [yellow]No Data (404)[/]\")\n",
    "                            success = False\n",
    "                            break \n",
    "\n",
    "                        response.raise_for_status()\n",
    "                        raw_data = response.json()\n",
    "                        \n",
    "                        # Handle Pagination\n",
    "                        if isinstance(raw_data, dict) and 'results' in raw_data:\n",
    "                            frames_list = raw_data['results']\n",
    "                        elif isinstance(raw_data, list):\n",
    "                            frames_list = raw_data\n",
    "                        else:\n",
    "                            frames_list = []\n",
    "\n",
    "                        success = True\n",
    "                        break\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"{log_prefix} | Network Error: {e}\")\n",
    "                        time.sleep(5 * (retry_count + 1))\n",
    "                        retry_count += 1\n",
    "                \n",
    "                if not success:\n",
    "                    break \n",
    "\n",
    "                if not frames_list:\n",
    "                    break \n",
    "\n",
    "                # --- LOOP DETECTION (Circuit Breaker) ---\n",
    "                if len(frames_list) > 0:\n",
    "                    first_frame = frames_list[0]\n",
    "                    page_sig = f\"{first_frame.get('timestamp')}_{first_frame.get('observation_id')}_{len(frames_list)}\"\n",
    "                    \n",
    "                    if page_sig in chunk_seen_hashes:\n",
    "                        logger.warning(f\"{log_prefix} | [red]Loop Detected[/] (API returned duplicate page). Stopping chunk.\")\n",
    "                        break\n",
    "                    chunk_seen_hashes.add(page_sig)\n",
    "                # ----------------------------------------\n",
    "\n",
    "                for frame in frames_list:\n",
    "                    f.write(json.dumps(frame) + '\\n')\n",
    "                    frames_downloaded += 1\n",
    "\n",
    "                # PAGINATION UPDATE\n",
    "                # Check for 'next' link. If present, use it for the next iteration.\n",
    "                next_link = raw_data.get('next')\n",
    "                if next_link:\n",
    "                    current_url = next_link\n",
    "                    current_params = None # Clear params since they are in the URL now\n",
    "                else:\n",
    "                    break # End of pages\n",
    "                \n",
    "        # Cleanup\n",
    "        if frames_downloaded == 0:\n",
    "            if outfile.exists() and outfile.stat().st_size == 0:\n",
    "                 outfile.unlink()\n",
    "                 if success:\n",
    "                     logger.info(f\"{log_prefix} | [yellow]Empty (0 frames)[/]\")\n",
    "        else:\n",
    "             logger.success(f\"{log_prefix} | Saved {frames_downloaded} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41268d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@logger.catch \n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"SatNOGS Downloader\")\n",
    "    parser.add_argument('--days', type=int, default=30, help=\"Days to look back\")\n",
    "    parser.add_argument('--norad', type=str, help=\"Single NORAD ID to fetch.\")\n",
    "    parser.add_argument('--all', action='store_true', help=\"Fetch ALL Golden Cohort satellites.\")\n",
    "    parser.add_argument('--start', type=str, help=\"Start YYYY-MM-DD\")\n",
    "    parser.add_argument('--end', type=str, help=\"End YYYY-MM-DD\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Target Selection Logic\n",
    "    if args.norad:\n",
    "        targets = {args.norad: TARGETS.get(args.norad, \"Manual Target\")}\n",
    "    elif args.all:\n",
    "        targets = TARGETS\n",
    "    else:\n",
    "        # Interactive Mode\n",
    "        logger.info(\"[bold]Interactive Mode[/]\")\n",
    "        print(\"\\n[?] Select Target:\")\n",
    "        opts = list(TARGETS.items())\n",
    "        for i, (nid, name) in enumerate(opts):\n",
    "            print(f\"    {i+1}. {name} ({nid})\")\n",
    "        print(\"    A. All Satellites (Default)\")\n",
    "        \n",
    "        choice = input(\"\\n> Select [A]: \").strip().upper()\n",
    "        \n",
    "        if choice == 'A' or choice == '':\n",
    "            targets = TARGETS\n",
    "            logger.info(\"Selected: [bold]All Satellites[/]\")\n",
    "        else:\n",
    "            try:\n",
    "                idx = int(choice) - 1\n",
    "                if 0 <= idx < len(opts):\n",
    "                    sel_nid, sel_name = opts[idx]\n",
    "                    targets = {sel_nid: sel_name}\n",
    "                    logger.info(f\"Selected: [bold]{sel_name}[/]\")\n",
    "                else:\n",
    "                    logger.error(\"Invalid selection number.\")\n",
    "                    sys.exit(1)\n",
    "            except ValueError:\n",
    "                logger.error(\"Invalid input.\")\n",
    "                sys.exit(1)\n",
    "\n",
    "        # Interactive Time Window (Only if not set via flags)\n",
    "        if not args.start and not args.end:\n",
    "            d_input = input(f\"\\n> Days to look back [{args.days}]: \").strip()\n",
    "            if d_input:\n",
    "                try:\n",
    "                    args.days = int(d_input)\n",
    "                except ValueError:\n",
    "                    logger.error(\"Invalid number for days.\")\n",
    "                    sys.exit(1)\n",
    "\n",
    "    # Time Window\n",
    "    if args.start and args.end:\n",
    "        start_dt = datetime.strptime(args.start, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
    "        end_dt = datetime.strptime(args.end, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
    "    else:\n",
    "        end_dt = datetime.now(timezone.utc)\n",
    "        start_dt = end_dt - timedelta(days=args.days)\n",
    "    \n",
    "    # Calculate Steps\n",
    "    total_days = (end_dt - start_dt).days\n",
    "    total_steps = total_days * len(targets)\n",
    "    \n",
    "    downloader = SatNOGSDownloader()\n",
    "\n",
    "    logger.info(f\"Targeting [bold]{len(targets)}[/] Satellites | Window: {start_dt.date()} -> {end_dt.date()}\")\n",
    "\n",
    "    # RICH PROGRESS BAR\n",
    "    with Progress(\n",
    "        SpinnerColumn(),\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        BarColumn(),\n",
    "        TextColumn(\"[progress.percentage]{task.percentage:>3.0f}%\"),\n",
    "        TimeRemainingColumn(),\n",
    "    ) as progress:\n",
    "        \n",
    "        main_task = progress.add_task(\"[green]Total Progress\", total=total_steps)\n",
    "        \n",
    "        current_dt = start_dt\n",
    "        while current_dt < end_dt:\n",
    "            chunk_end = current_dt + timedelta(days=CHUNK_SIZE_DAYS)\n",
    "            if chunk_end > end_dt: chunk_end = end_dt\n",
    "\n",
    "            for norad_id, name in targets.items():\n",
    "                downloader.download_chunk(\n",
    "                    norad_id, \n",
    "                    current_dt, \n",
    "                    chunk_end, \n",
    "                    main_task, \n",
    "                    progress\n",
    "                )\n",
    "                progress.advance(main_task)\n",
    "            \n",
    "            current_dt = chunk_end\n",
    "\n",
    "    logger.success(\"Download Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d272b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
