{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e00d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from rich.logging import RichHandler\n",
    "from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the core logic\n",
    "from gr_sat.telemetry import process_frame, TelemetryFrame\n",
    "# Import decoders to trigger registration\n",
    "import gr_sat.decoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac67c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "RAW_DIR = Path(\"data/raw\")\n",
    "PROCESSED_DIR = Path(\"data/processed\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10caf144",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Configure Logger\n",
    "logger.configure(handlers=[\n",
    "    {\"sink\": RichHandler(show_time=False), \"format\": \"{message}\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4640f18c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_jsonl(filepath: Path) -> List[Dict]:\n",
    "    \"\"\"Reads a JSONL file and returns a list of dicts.\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90fb4d1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_satellite(norad_id: str):\n",
    "    \"\"\"\n",
    "    Processes all raw data for a specific satellite and saves a Parquet file.\n",
    "    \"\"\"\n",
    "    sat_dir = RAW_DIR / str(norad_id)\n",
    "    if not sat_dir.exists():\n",
    "        logger.warning(f\"No raw data found for NORAD ID {norad_id}\")\n",
    "        return\n",
    "\n",
    "    json_files = sorted(list(sat_dir.glob(\"*.jsonl\")))\n",
    "    if not json_files:\n",
    "        logger.warning(f\"No .jsonl files found in {sat_dir}\")\n",
    "        return\n",
    "\n",
    "    valid_frames = []\n",
    "    total_frames = 0\n",
    "    decoded_count = 0\n",
    "\n",
    "    logger.info(f\"Processing {len(json_files)} files for Satellite {norad_id}...\")\n",
    "\n",
    "    for jp in json_files:\n",
    "        raw_records = load_jsonl(jp)\n",
    "        total_frames += len(raw_records)\n",
    "        \n",
    "        for record in raw_records:\n",
    "            # SatNOGS API usually provides 'frame' as a hex string\n",
    "            hex_payload = record.get('frame')\n",
    "            timestamp_str = record.get('timestamp')\n",
    "            \n",
    "            if not hex_payload or not timestamp_str:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Convert hex to bytes\n",
    "                payload_bytes = bytes.fromhex(hex_payload)\n",
    "                \n",
    "                # Parse timestamp\n",
    "                # Format: \"2024-01-01T12:00:00Z\"\n",
    "                ts = datetime.fromisoformat(timestamp_str.replace(\"Z\", \"+00:00\"))\n",
    "                \n",
    "                # Use the Shared Core to process\n",
    "                tf = process_frame(\n",
    "                    norad_id=int(norad_id), \n",
    "                    payload=payload_bytes, \n",
    "                    source=\"satnogs_db\", \n",
    "                    timestamp=ts\n",
    "                )\n",
    "                \n",
    "                if tf:\n",
    "                    valid_frames.append(tf.to_dict())\n",
    "                    decoded_count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # logger.debug(f\"Frame error: {e}\")\n",
    "                continue\n",
    "\n",
    "    if not valid_frames:\n",
    "        logger.warning(f\"No valid frames decoded for {norad_id} out of {total_frames} raw frames.\")\n",
    "        return\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(valid_frames)\n",
    "    \n",
    "    # Deduplicate (by timestamp)\n",
    "    initial_len = len(df)\n",
    "    df.drop_duplicates(subset=['timestamp'], keep='first', inplace=True)\n",
    "    dedup_len = len(df)\n",
    "    \n",
    "    # Sort\n",
    "    df.sort_values('timestamp', inplace=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    out_file = PROCESSED_DIR / f\"{norad_id}.csv\"\n",
    "    df.to_csv(out_file, index=False)\n",
    "    \n",
    "    logger.success(f\"Saved {dedup_len} frames to {out_file} (discarded {initial_len - dedup_len} dupes). Decode Rate: {decoded_count}/{total_frames} ({decoded_count/total_frames:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c9fa3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Telemetry Processor\")\n",
    "    parser.add_argument(\"--norad\", type=str, help=\"Specific NORAD ID to process\")\n",
    "    parser.add_argument(\"--all\", action=\"store_true\", help=\"Process all available satellites\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.norad:\n",
    "        process_satellite(args.norad)\n",
    "    elif args.all:\n",
    "        # List all directories in data/raw\n",
    "        sat_dirs = [d.name for d in RAW_DIR.iterdir() if d.is_dir()]\n",
    "        for sat_id in sat_dirs:\n",
    "            process_satellite(sat_id)\n",
    "    else:\n",
    "        logger.info(\"Please specify --norad <ID> or --all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238377a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
